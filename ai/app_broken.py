from flask import Flask, request, jsonify
import os
import logging
import random

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Simplified Vietnamese Tutor AI without heavy dependencies
# We'll use rule-based responses until model dependencies are resolved

def generate_intelligent_response(user_input):
    """Generate intelligent Vietnamese tutoring responses"""
    user_lower = user_input.lower().strip()
    
    # Vietnamese greetings
    if any(word in user_lower for word in ['xin chÃ o', 'hello', 'hi', 'chÃ o', 'chÃ o báº¡n']):
        responses = [
            "Xin chÃ o! TÃ´i lÃ  AI gia sÆ° tiáº¿ng Viá»‡t cá»§a báº¡n. TÃ´i cÃ³ thá»ƒ giÃºp báº¡n há»c:\nâ€¢ Tá»« vá»±ng vÃ  ngá»¯ phÃ¡p\nâ€¢ PhÃ¡t Ã¢m chuáº©n\nâ€¢ VÄƒn hÃ³a Viá»‡t Nam\nâ€¢ Giao tiáº¿p hÃ ng ngÃ y\n\nBáº¡n muá»‘n báº¯t Ä‘áº§u há»c gÃ¬?",
            "ChÃ o báº¡n! Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n. HÃ´m nay chÃºng ta sáº½ cÃ¹ng khÃ¡m phÃ¡ tiáº¿ng Viá»‡t nhÃ©! Báº¡n Ä‘Ã£ biáº¿t nhá»¯ng tá»« tiáº¿ng Viá»‡t nÃ o chÆ°a?"
        ]
        return random.choice(responses)
    
    # Thanks responses
    elif any(word in user_lower for word in ['cáº£m Æ¡n', 'cÃ¡m Æ¡n', 'thank you', 'thanks']):
        responses = [
            "Ráº¥t vui Ä‘Æ°á»£c giÃºp báº¡n! ğŸ˜Š Há»c tiáº¿ng Viá»‡t cáº§n kiÃªn nháº«n, nhÆ°ng tÃ´i tin báº¡n sáº½ thÃ nh cÃ´ng. CÃ²n gÃ¬ khÃ¡c tÃ´i cÃ³ thá»ƒ giÃºp khÃ´ng?",
            "KhÃ´ng cÃ³ gÃ¬! ÄÃ³ lÃ  niá»m vui cá»§a tÃ´i. Báº¡n cÃ³ muá»‘n há»c thÃªm cÃ¡ch nÃ³i 'cáº£m Æ¡n' trong cÃ¡c tÃ¬nh huá»‘ng khÃ¡c nhau khÃ´ng?"
        ]
        return random.choice(responses)
    
    # Handle complaints/negative feedback
    elif any(word in user_lower for word in ['ngu ngá»‘c', 'stupid', 'tá»‡', 'xáº¥u', 'khÃ´ng tá»‘t', 'bad', 'pháº£n há»“i']):
        return "Xin lá»—i báº¡n ráº¥t nhiá»u! ğŸ™ TÃ´i thá»±c sá»± muá»‘n cáº£i thiá»‡n Ä‘á»ƒ giÃºp báº¡n há»c tá»‘t hÆ¡n.\n\nHÃ£y cho tÃ´i biáº¿t:\nâ€¢ Báº¡n muá»‘n há»c chá»§ Ä‘á» gÃ¬?\nâ€¢ TÃ´i cÃ³ thá»ƒ giáº£i thÃ­ch rÃµ hÆ¡n Ä‘iá»u gÃ¬?\nâ€¢ Báº¡n cáº§n há»— trá»£ gÃ¬ cá»¥ thá»ƒ?\n\nTÃ´i sáº½ cá»‘ gáº¯ng pháº£n há»“i chÃ­nh xÃ¡c vÃ  há»¯u Ã­ch hÆ¡n!"
    
    # Learning topics
    elif any(word in user_lower for word in ['há»c', 'learn', 'study', 'dáº¡y', 'teach']):
        return "Tuyá»‡t vá»i! Báº¡n muá»‘n há»c tiáº¿ng Viá»‡t. ChÃºng ta cÃ³ thá»ƒ báº¯t Ä‘áº§u vá»›i:\n\nğŸ—£ï¸ **PhÃ¡t Ã¢m cÆ¡ báº£n:**\n- 6 thanh Ä‘iá»‡u tiáº¿ng Viá»‡t\n- CÃ¡ch phÃ¡t Ã¢m Ä‘Ãºng\n\nğŸ“š **Tá»« vá»±ng thiáº¿t yáº¿u:**\n- ChÃ o há»i vÃ  giá»›i thiá»‡u\n- Sá»‘ Ä‘áº¿m vÃ  thá»i gian\n- Gia Ä‘Ã¬nh vÃ  cÃ´ng viá»‡c\n\nğŸ­ **VÄƒn hÃ³a vÃ  giao tiáº¿p:**\n- PhÃ©p lá»‹ch sá»± Viá»‡t Nam\n- CÃ¡ch xÆ°ng hÃ´ phÃ¹ há»£p\n\nBáº¡n muá»‘n báº¯t Ä‘áº§u tá»« Ä‘Ã¢u?"
    
    # Pronunciation
    elif any(word in user_lower for word in ['phÃ¡t Ã¢m', 'pronunciation', 'thanh Ä‘iá»‡u', 'tone']):
        return "Tiáº¿ng Viá»‡t cÃ³ 6 thanh Ä‘iá»‡u quan trá»ng:\n\n1. **Thanh ngang** (khÃ´ng dáº¥u): ma\n2. **Thanh huyá»n** (dáº¥u `): mÃ   \n3. **Thanh sáº¯c** (dáº¥u Â´): mÃ¡\n4. **Thanh há»i** (dáº¥u ?): máº£\n5. **Thanh ngÃ£** (dáº¥u ~): mÃ£\n6. **Thanh náº·ng** (dáº¥u .): máº¡\n\nğŸ’¡ **Máº¹o nhá»›:** HÃ£y thá»­ phÃ¡t Ã¢m 6 tá»« nÃ y - chÃºng cÃ³ nghÄ©a hoÃ n toÃ n khÃ¡c nhau:\n- ma (ghost) - mÃ  (but) - mÃ¡ (cheek) - máº£ (grave) - mÃ£ (code) - máº¡ (rice seedling)\n\nBáº¡n thá»­ phÃ¡t Ã¢m xem sao?"
    
    # Vocabulary
    elif any(word in user_lower for word in ['tá»« vá»±ng', 'vocabulary', 'tá»«', 'word']):
        return "HÃ£y há»c tá»« vá»±ng cÆ¡ báº£n theo chá»§ Ä‘á»:\n\nğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **Gia Ä‘Ã¬nh:**\n- Bá»‘/Cha = Father\n- Máº¹/MÃ¡ = Mother\n- Anh = Older brother\n- Chá»‹ = Older sister\n- Em = Younger sibling\n\nğŸœ **Äá»“ Äƒn phá»• biáº¿n:**\n- CÆ¡m = Rice\n- Phá»Ÿ = Pho soup\n- BÃ¡nh mÃ¬ = Vietnamese sandwich\n- Cháº£ cÃ¡ = Grilled fish\n- CÃ  phÃª = Coffee\n\nBáº¡n muá»‘n há»c chá»§ Ä‘á» nÃ o khÃ¡c?"
    
    # Numbers
    elif any(word in user_lower for word in ['sá»‘', 'number', 'Ä‘áº¿m', 'count']):
        return "Há»c Ä‘áº¿m sá»‘ tiáº¿ng Viá»‡t:\n\n**Sá»‘ cÆ¡ báº£n 1-10:**\n1ï¸âƒ£ Má»™t (mohdt)\n2ï¸âƒ£ Hai (high)\n3ï¸âƒ£ Ba (bah)\n4ï¸âƒ£ Bá»‘n (bohn)\n5ï¸âƒ£ NÄƒm (nahm)\n6ï¸âƒ£ SÃ¡u (shah-oo)\n7ï¸âƒ£ Báº£y (by)\n8ï¸âƒ£ TÃ¡m (tahm)\n9ï¸âƒ£ ChÃ­n (cheen)\nğŸ”Ÿ MÆ°á»i (moo-uhr-ee)\n\n**Sá»‘ lá»›n:**\n- 100 = Má»™t trÄƒm\n- 1000 = Má»™t ngÃ n\n- 10000 = Má»™t váº¡n\n\nBáº¡n thá»­ Ä‘áº¿m tá»« 1-10 xem!"
    
    # Culture
    elif any(word in user_lower for word in ['vÄƒn hÃ³a', 'culture', 'truyá»n thá»‘ng', 'tradition']):
        return "VÄƒn hÃ³a Viá»‡t Nam tháº­t phong phÃº! ğŸ‡»ğŸ‡³\n\nğŸ­ **Äáº·c trÆ°ng vÄƒn hÃ³a:**\n- TÃ´n trá»ng ngÆ°á»i lá»›n tuá»•i\n- Gia Ä‘Ã¬nh lÃ  trung tÃ¢m\n- Hiáº¿u khÃ¡ch vÃ  thÃ¢n thiá»‡n\n- Trá»ng nghÄ©a tÃ¬nh\n\nğŸŠ **Lá»… há»™i truyá»n thá»‘ng:**\n- Táº¿t NguyÃªn ÄÃ¡n (Lunar New Year)\n- Táº¿t Trung Thu (Mid-Autumn Festival)\n- Lá»… Vu Lan (Ghost Festival)\n\nğŸœ **áº¨m thá»±c Ä‘áº·c sáº¯c:**\n- Phá»Ÿ, BÃºn BÃ² Huáº¿, CÆ¡m Táº¥m\n- BÃ¡nh MÃ¬, Cháº£ CÃ¡, Nem NÆ°á»›ng\n\nBáº¡n muá»‘n tÃ¬m hiá»ƒu vá» khÃ­a cáº¡nh nÃ o?"
    
    # Default intelligent response
    else:
        responses = [
            f"Báº¡n vá»«a nÃ³i '{user_input}'. ÄÃ¢y lÃ  cÆ¡ há»™i tá»‘t Ä‘á»ƒ cáº£i thiá»‡n tiáº¿ng Viá»‡t!\n\nğŸ” **TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:**\nâ€¢ Sá»­a ngá»¯ phÃ¡p náº¿u cáº§n\nâ€¢ Giáº£i thÃ­ch tá»« khÃ³\nâ€¢ Gá»£i Ã½ cÃ¡ch diá»…n Ä‘áº¡t hay hÆ¡n\nâ€¢ Dáº¡y thÃªm tá»« vá»±ng liÃªn quan\n\nBáº¡n muá»‘n tÃ´i táº­p trung vÃ o Ä‘iá»u gÃ¬?",
            
            f"ThÃº vá»‹! CÃ¢u '{user_input}' cá»§a báº¡n cÃ³ thá»ƒ Ä‘Æ°á»£c cáº£i thiá»‡n.\n\nğŸ“ **HÃ£y thá»­ phÃ¢n tÃ­ch:**\nâ€¢ Ã chÃ­nh báº¡n muá»‘n truyá»n Ä‘áº¡t?\nâ€¢ CÃ³ tá»« nÃ o khÃ³ phÃ¡t Ã¢m khÃ´ng?\nâ€¢ Ngá»¯ cáº£nh sá»­ dá»¥ng lÃ  gÃ¬?\n\nğŸ’¡ TÃ´i sáº½ giÃºp báº¡n diá»…n Ä‘áº¡t tá»± nhiÃªn hÆ¡n!",
            
            f"Hay láº¯m! '{user_input}' - tÃ´i hiá»ƒu báº¡n Ä‘ang luyá»‡n táº­p.\n\nğŸ¯ **CÃ¹ng cáº£i thiá»‡n:**\nâ€¢ PhÃ¡t Ã¢m chuáº©n hÆ¡n\nâ€¢ Tá»« vá»±ng phong phÃº hÆ¡n\nâ€¢ Ngá»¯ phÃ¡p chÃ­nh xÃ¡c hÆ¡n\nâ€¢ Giao tiáº¿p tá»± nhiÃªn hÆ¡n\n\nBáº¡n muá»‘n báº¯t Ä‘áº§u tá»« Ä‘Ã¢u?"
        ]
        return random.choice(responses)

def load_model():
    """Placeholder for model loading - using intelligent rule-based system"""
    logger.info("Using intelligent rule-based Vietnamese tutoring system")
    return True
        
        logger.info("Model loaded successfully!")
        return True
        
    except Exception as e:
        logger.error(f"Failed to load model: {str(e)}")
        return False

def generate_response(user_input, max_length=512):
    """Generate AI response using PhoGPT"""
    if not tokenizer or not model:
        return "Xin lá»—i, há»‡ thá»‘ng AI chÆ°a sáºµn sÃ ng."
    
    try:
        # Improved Vietnamese tutoring prompt
        system_prompt = """Báº¡n lÃ  má»™t giÃ¡o viÃªn tiáº¿ng Viá»‡t thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p, dáº¡y tiáº¿ng Viá»‡t cho ngÆ°á»i nÆ°á»›c ngoÃ i. HÃ£y:

1. Tráº£ lá»i má»™t cÃ¡ch tá»± nhiÃªn, thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch
2. Giáº£i thÃ­ch rÃµ rÃ ng, dá»… hiá»ƒu
3. ÄÆ°a ra vÃ­ dá»¥ cá»¥ thá»ƒ khi cáº§n
4. Khuyáº¿n khÃ­ch há»c viÃªn
5. Sá»­a lá»—i má»™t cÃ¡ch tÃ­ch cá»±c

"""
        
        # Create contextual prompt based on user input
        if any(greeting in user_input.lower() for greeting in ['xin chÃ o', 'hello', 'hi', 'chÃ o']):
            context = "ÄÃ¢y lÃ  lá»i chÃ o. HÃ£y pháº£n há»“i thÃ¢n thiá»‡n vÃ  cÃ³ thá»ƒ dáº¡y thÃªm vá» cÃ¡ch chÃ o há»i trong tiáº¿ng Viá»‡t."
        elif any(word in user_input.lower() for word in ['cáº£m Æ¡n', 'thank you', 'thanks', 'cÃ¡m Æ¡n']):
            context = "ÄÃ¢y lÃ  lá»i cáº£m Æ¡n. HÃ£y pháº£n há»“i lá»‹ch sá»± vÃ  cÃ³ thá»ƒ dáº¡y vá» cÃ¡ch cáº£m Æ¡n trong tiáº¿ng Viá»‡t."
        elif any(word in user_input.lower() for word in ['pháº£n há»“i', 'response', 'reply']):
            context = "Há»c viÃªn Ä‘ang tháº¯c máº¯c vá» pháº£n há»“i. HÃ£y giáº£i thÃ­ch vÃ  tÆ°Æ¡ng tÃ¡c tÃ­ch cá»±c."
        elif any(word in user_input.lower() for word in ['ngu ngá»‘c', 'stupid', 'bad', 'tá»‡']):
            context = "Há»c viÃªn cÃ³ váº» khÃ´ng hÃ i lÃ²ng. HÃ£y xin lá»—i, giáº£i thÃ­ch vÃ  cáº£i thiá»‡n cÃ¡ch pháº£n há»“i."
        else:
            context = "HÃ£y pháº£n há»“i nhÆ° má»™t giÃ¡o viÃªn tiáº¿ng Viá»‡t chuyÃªn nghiá»‡p vÃ  há»— trá»£ há»c viÃªn tá»‘t nháº¥t."
        
        # Format the prompt properly
        formatted_input = f"""<s>[INST] {system_prompt}

{context}

CÃ¢u nÃ³i cá»§a há»c viÃªn: "{user_input}"

HÃ£y pháº£n há»“i má»™t cÃ¡ch thÃ´ng minh, há»¯u Ã­ch vÃ  phÃ¹ há»£p: [/INST]"""
        
        # Tokenize input
        inputs = tokenizer.encode(formatted_input, return_tensors="pt")
        
        if DEVICE != "cpu":
            inputs = inputs.to(model.device)
        
        # Generate response with better parameters
        with torch.no_grad():
            outputs = model.generate(
                inputs,
                max_length=len(inputs[0]) + 256,
                temperature=0.8,
                do_sample=True,
                top_p=0.9,
                top_k=40,
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id,
                repetition_penalty=1.2,
                no_repeat_ngram_size=3
            )
        
        # Decode response
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # Extract only the response part after [/INST]
        if "[/INST]" in response:
            response = response.split("[/INST]")[-1].strip()
        
        # Clean up response
        response = response.strip()
        
        # Ensure response is appropriate
        if not response or len(response) < 10:
            return "Xin chÃ o! TÃ´i lÃ  AI giÃ¡o viÃªn tiáº¿ng Viá»‡t cá»§a báº¡n. TÃ´i á»Ÿ Ä‘Ã¢y Ä‘á»ƒ giÃºp báº¡n há»c tiáº¿ng Viá»‡t má»™t cÃ¡ch hiá»‡u quáº£. Báº¡n cÃ³ cÃ¢u há»i gÃ¬ vá» tiáº¿ng Viá»‡t khÃ´ng?"
        
        return response
        
    except Exception as e:
        logger.error(f"Error generating response: {str(e)}")
        return "Xin lá»—i, tÃ´i Ä‘ang gáº·p má»™t chÃºt trá»¥c tráº·c ká»¹ thuáº­t. TÃ´i sáº½ cá»‘ gáº¯ng pháº£n há»“i tá»‘t hÆ¡n. Báº¡n cÃ³ thá»ƒ thá»­ há»i láº¡i khÃ´ng?"

# Smart fallback responses for Vietnamese tutoring
SMART_RESPONSES = {
    'greeting': [
        "Xin chÃ o! TÃ´i lÃ  AI giÃ¡o viÃªn tiáº¿ng Viá»‡t cá»§a báº¡n. TÃ´i ráº¥t vui Ä‘Æ°á»£c giÃºp báº¡n há»c tiáº¿ng Viá»‡t! ğŸ‘‹",
        "ChÃ o báº¡n! HÃ´m nay chÃºng ta sáº½ há»c gÃ¬ vá» tiáº¿ng Viá»‡t nhá»‰? ğŸ˜Š",
        "Hello! TÃ´i cÃ³ thá»ƒ giÃºp báº¡n luyá»‡n táº­p tiáº¿ng Viá»‡t. Báº¡n muá»‘n há»c vá» chá»§ Ä‘á» gÃ¬?"
    ],
    'thanks': [
        "KhÃ´ng cÃ³ chi! TÃ´i ráº¥t vui Ä‘Æ°á»£c giÃºp báº¡n há»c tiáº¿ng Viá»‡t. ğŸ˜Š",
        "Ráº¥t vinh dá»± Ä‘Æ°á»£c há»— trá»£ báº¡n! CÃ²n cÃ¢u há»i nÃ o khÃ¡c khÃ´ng?",
        "Cáº£m Æ¡n báº¡n! HÃ£y tiáº¿p tá»¥c luyá»‡n táº­p nhÃ©!"
    ],
    'complaint': [
        "Xin lá»—i báº¡n! TÃ´i sáº½ cá»‘ gáº¯ng pháº£n há»“i tá»‘t hÆ¡n. TÃ´i Ä‘ang há»c cÃ¡ch trá»Ÿ thÃ nh giÃ¡o viÃªn giá»i hÆ¡n tá»« feedback cá»§a báº¡n. ğŸ™",
        "TÃ´i xin lá»—i vÃ¬ pháº£n há»“i chÆ°a tá»‘t. Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t báº¡n mong muá»‘n tÃ´i giáº£i thÃ­ch nhÆ° tháº¿ nÃ o khÃ´ng?",
        "Cáº£m Æ¡n gÃ³p Ã½ cá»§a báº¡n! TÃ´i sáº½ cáº£i thiá»‡n. Báº¡n cÃ³ muá»‘n tÃ´i giáº£i thÃ­ch láº¡i má»™t cÃ¡ch khÃ¡c khÃ´ng?"
    ],
    'encouragement': [
        "Báº¡n Ä‘ang há»c ráº¥t tá»‘t! Tiáº¿p tá»¥c cá»‘ gáº¯ng nhÃ©! ğŸ’ª",
        "Tuyá»‡t vá»i! Viá»‡c luyá»‡n táº­p tiáº¿ng Viá»‡t Ä‘Ã²i há»i kiÃªn nháº«n, nhÆ°ng báº¡n lÃ m ráº¥t tá»‘t!",
        "Äá»«ng náº£n lÃ²ng! Má»—i cÃ¢u nÃ³i Ä‘á»u giÃºp báº¡n tiáº¿n bá»™ trong viá»‡c há»c tiáº¿ng Viá»‡t!"
    ],
    'default': [
        "TÃ´i hiá»ƒu báº¡n Ä‘ang muá»‘n há»c tiáº¿ng Viá»‡t. Báº¡n cÃ³ thá»ƒ há»i tÃ´i vá» tá»« vá»±ng, ngá»¯ phÃ¡p, phÃ¡t Ã¢m, hay vÄƒn hÃ³a Viá»‡t Nam! ğŸ“š",
        "Ráº¥t thÃº vá»‹! HÃ£y cÃ¹ng khÃ¡m phÃ¡ tiáº¿ng Viá»‡t nhÃ©. Báº¡n muá»‘n tÃ´i giáº£i thÃ­ch gÃ¬?",
        "Tiáº¿ng Viá»‡t lÃ  ngÃ´n ngá»¯ tuyá»‡t vá»i! TÃ´i cÃ³ thá»ƒ giÃºp báº¡n vá»›i phÃ¡t Ã¢m, tá»« vá»±ng, hoáº·c giao tiáº¿p hÃ ng ngÃ y."
    ]
}

def get_smart_response(user_input):
    """Get contextual smart response based on user input"""
    import random
    
    user_lower = user_input.lower()
    
    # Detect greeting
    if any(word in user_lower for word in ['xin chÃ o', 'chÃ o', 'hello', 'hi', 'hey']):
        return random.choice(SMART_RESPONSES['greeting'])
    
    # Detect thanks
    elif any(word in user_lower for word in ['cáº£m Æ¡n', 'cÃ¡m Æ¡n', 'thank you', 'thanks']):
        return random.choice(SMART_RESPONSES['thanks'])
    
    # Detect complaint
    elif any(word in user_lower for word in ['ngu ngá»‘c', 'stupid', 'tá»‡', 'xáº¥u', 'khÃ´ng tá»‘t', 'bad']):
        return random.choice(SMART_RESPONSES['complaint'])
    
    # Detect need for encouragement
    elif any(word in user_lower for word in ['khÃ³', 'difficult', 'khÃ´ng hiá»ƒu', 'confused', 'help']):
        return random.choice(SMART_RESPONSES['encouragement'])
    
    # Default educational response
    else:
        return random.choice(SMART_RESPONSES['default'])

@app.route('/', methods=['GET'])
def health_check():
    """Health check endpoint"""
    model_status = "loaded" if model and tokenizer else "not loaded"
    return jsonify({
        "status": "running",
        "model": MODEL_NAME,
        "device": DEVICE,
        "model_status": model_status
    })

@app.route('/chat', methods=['POST'])
def chat():
    """Main chat endpoint"""
    try:
        data = request.get_json()
        
        if not data or 'message' not in data:
            return jsonify({"error": "Message is required"}), 400
        
        user_message = data['message'].strip()
        
        if not user_message:
            return jsonify({"error": "Message cannot be empty"}), 400
        
        # Try PhoGPT first, fallback to smart responses
        try:
            ai_response = generate_response(user_message)
            
            # If PhoGPT response is too generic or empty, use smart response
            if not ai_response or len(ai_response.strip()) < 20 or "xin lá»—i" in ai_response.lower():
                ai_response = get_smart_response(user_message)
                logger.info("Used smart fallback response")
            
        except Exception as model_error:
            logger.warning(f"PhoGPT failed: {model_error}, using smart response")
            ai_response = get_smart_response(user_message)
        
        return jsonify({
            "response": ai_response,
            "model": MODEL_NAME,
            "device": DEVICE,
            "response_type": "smart_ai"
        })
        
    except Exception as e:
        logger.error(f"Error in chat endpoint: {str(e)}")
        return jsonify({"error": "Internal server error"}), 500

@app.route('/model/reload', methods=['POST'])
def reload_model():
    """Reload model endpoint"""
    success = load_model()
    if success:
        return jsonify({"message": "Model reloaded successfully"})
    else:
        return jsonify({"error": "Failed to reload model"}), 500

# Educational prompts for Vietnamese learning
VIETNAMESE_LEARNING_PROMPTS = {
    "greeting": "### CÃ¢u há»i: HÃ£y dáº¡y tÃ´i cÃ¡ch chÃ o há»i báº±ng tiáº¿ng Viá»‡t trong cÃ¡c tÃ¬nh huá»‘ng khÃ¡c nhau\n### Tráº£ lá»i:",
    "pronunciation": "### CÃ¢u há»i: HÃ£y giáº£i thÃ­ch cÃ¡ch phÃ¡t Ã¢m tiáº¿ng Viá»‡t cho ngÆ°á»i nÆ°á»›c ngoÃ i\n### Tráº£ lá»i:",
    "culture": "### CÃ¢u há»i: HÃ£y giáº£i thÃ­ch vá» vÄƒn hÃ³a Viá»‡t Nam má»™t cÃ¡ch Ä‘Æ¡n giáº£n\n### Tráº£ lá»i:",
}

@app.route('/learn/<topic>', methods=['GET'])
def learn_topic(topic):
    """Get learning content for specific topics"""
    if topic not in VIETNAMESE_LEARNING_PROMPTS:
        return jsonify({"error": "Topic not found"}), 404
    
    prompt = VIETNAMESE_LEARNING_PROMPTS[topic]
    response = generate_response(prompt)
    
    return jsonify({
        "topic": topic,
        "content": response
    })

if __name__ == '__main__':
    logger.info("Starting PhoGPT AI Service...")
    
    # Load model on startup
    if load_model():
        logger.info("Model loaded successfully. Starting Flask app...")
        app.run(host='0.0.0.0', port=5000, debug=False)
    else:
        logger.error("Failed to load model. Exiting...")
        exit(1)