#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Hybrid Vietnamese Teacher - Best of both worlds
- Use cloud API for complex queries (OpenAI/Cohere/Claude)
- Use local small model for simple responses
- Smart fallback system
"""

import openai
import requests
from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import json
from datetime import datetime

app = Flask(__name__)
CORS(app)

# API Configuration (set your API keys)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
COHERE_API_KEY = os.getenv("COHERE_API_KEY", "")

class HybridVietnameseTeacher:
    def __init__(self):
        self.conversation_history = []
        self.local_responses = self.load_local_responses()
        
    def load_local_responses(self):
        """Load pre-defined responses for common queries"""
        try:
            with open('premium_teacher_data.txt', 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse into Q&A pairs
            responses = {}
            lines = content.split('\n')
            current_question = ""
            
            for line in lines:
                line = line.strip()
                if line.startswith('Há»c viÃªn:'):
                    current_question = line.replace('Há»c viÃªn:', '').strip()
                elif line.startswith('GiÃ¡o viÃªn:') and current_question:
                    answer = line.replace('GiÃ¡o viÃªn:', '').strip()
                    responses[current_question.lower()] = answer
                    current_question = ""
            
            print(f"ðŸ“š Loaded {len(responses)} local responses")
            return responses
            
        except FileNotFoundError:
            print("âš ï¸ premium_teacher_data.txt not found, using basic responses")
            return {}
    
    def find_local_response(self, user_message):
        """Find matching local response using keyword matching"""
        user_lower = user_message.lower()
        
        # Direct matching
        if user_lower in self.local_responses:
            return self.local_responses[user_lower]
        
        # Keyword matching
        for question, answer in self.local_responses.items():
            # Extract key words
            user_words = set(user_lower.split())
            question_words = set(question.split())
            
            # If significant overlap, return this answer
            overlap = len(user_words.intersection(question_words))
            if overlap >= 2 and len(user_words) <= 10:  # For short questions
                return answer
        
        # Pattern matching for common topics
        keywords_responses = {
            ['phÃ¡t Ã¢m', 'pronunciation']: "PhÃ¡t Ã¢m lÃ  ná»n táº£ng quan trá»ng nháº¥t cá»§a tiáº¿ng Viá»‡t em áº¡! Tiáº¿ng Viá»‡t cÃ³ 6 thanh Ä‘iá»‡u: ngang (ba), huyá»n (bÃ ), sáº¯c (bÃ¡), há»i (báº£), ngÃ£ (bÃ£), vÃ  náº·ng (báº¡). ChÃºng ta sáº½ luyá»‡n tá»«ng bÆ°á»›c má»™t nhÃ©!",
            ['thanh Ä‘iá»‡u', 'tones']: "6 thanh Ä‘iá»‡u trong tiáº¿ng Viá»‡t: thanh ngang (ba), thanh huyá»n (bÃ ), thanh sáº¯c (bÃ¡), thanh há»i (báº£), thanh ngÃ£ (bÃ£), vÃ  thanh náº·ng (báº¡). Má»—i thanh cÃ³ giai Ä‘iá»‡u riÃªng, em cáº§n luyá»‡n thÆ°á»ng xuyÃªn.",
            ['tá»« vá»±ng', 'vocabulary']: "Há»c tá»« vá»±ng hiá»‡u quáº£ nháº¥t lÃ  há»c theo chá»§ Ä‘á» em áº¡! VÃ­ dá»¥: gia Ä‘Ã¬nh, thá»©c Äƒn, quáº§n Ã¡o. Má»—i ngÃ y há»c 5-8 tá»« má»›i vÃ  táº¡o cÃ¢u vá»›i nhá»¯ng tá»« Ä‘Ã³.",
            ['ngáº¡i ngÃ¹ng', 'shy', 'sá»£']: "ÄÃ³ lÃ  cáº£m giÃ¡c bÃ¬nh thÆ°á»ng em Ã ! Äá»«ng sá»£ sai, cá»© thá»­ nÃ³i. NgÆ°á»i Viá»‡t ráº¥t hiá»n, há» sáº½ giÃºp em sá»­a lá»—i má»™t cÃ¡ch tá»­ táº¿. Chá»‰ báº±ng cÃ¡ch nÃ³i nhiá»u, em má»›i tiáº¿n bá»™ Ä‘Æ°á»£c.",
            ['xin chÃ o', 'hello', 'chÃ o']: "Xin chÃ o em! CÃ´ ráº¥t vui Ä‘Æ°á»£c gáº·p em hÃ´m nay. Em muá»‘n há»c gÃ¬ vá» tiáº¿ng Viá»‡t?",
            ['cáº£m Æ¡n', 'thank']: "KhÃ´ng cÃ³ gÃ¬ em! Há»c ngÃ´n ngá»¯ lÃ  hÃ nh trÃ¬nh thÃº vá»‹. CÃ´ tin ráº±ng vá»›i sá»± kiÃªn trÃ¬, em sáº½ nÃ³i tiáº¿ng Viá»‡t ráº¥t tá»± nhiÃªn!"
        }
        
        for keywords, response in keywords_responses.items():
            if any(keyword in user_lower for keyword in keywords):
                return response
        
        return None
    
    def call_openai_api(self, user_message):
        """Use OpenAI API for complex responses"""
        if not OPENAI_API_KEY:
            return None
        
        try:
            # System prompt for Vietnamese teacher
            system_prompt = """Báº¡n lÃ  má»™t giÃ¡o viÃªn tiáº¿ng Viá»‡t chuyÃªn nghiá»‡p, nhiá»‡t tÃ¬nh vÃ  kiÃªn nháº«n. 
            HÃ£y tráº£ lá»i há»c sinh báº±ng tiáº¿ng Viá»‡t má»™t cÃ¡ch tá»± nhiÃªn, há»¯u Ã­ch vÃ  khuyáº¿n khÃ­ch. 
            Giáº£i thÃ­ch rÃµ rÃ ng, Ä‘Æ°a vÃ­ dá»¥ cá»¥ thá»ƒ, vÃ  luÃ´n Ä‘á»™ng viÃªn há»c sinh."""
            
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"OpenAI API error: {e}")
            return None
    
    def call_cohere_api(self, user_message):
        """Alternative: Use Cohere API"""
        if not COHERE_API_KEY:
            return None
        
        try:
            headers = {
                'Authorization': f'Bearer {COHERE_API_KEY}',
                'Content-Type': 'application/json'
            }
            
            prompt = f"""Báº¡n lÃ  giÃ¡o viÃªn tiáº¿ng Viá»‡t chuyÃªn nghiá»‡p. Tráº£ lá»i há»c sinh:
            
Há»c sinh: {user_message}
GiÃ¡o viÃªn:"""
            
            data = {
                'model': 'command-light',  # Smaller, cheaper model
                'prompt': prompt,
                'max_tokens': 150,
                'temperature': 0.7
            }
            
            response = requests.post(
                'https://api.cohere.ai/v1/generate',
                headers=headers,
                json=data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['generations'][0]['text'].strip()
            
        except Exception as e:
            print(f"Cohere API error: {e}")
            return None
    
    def generate_response(self, user_message):
        """Smart response generation with fallback"""
        
        # Step 1: Try local response first (fast + free)
        local_response = self.find_local_response(user_message)
        if local_response:
            return local_response, "local"
        
        # Step 2: For complex queries, try cloud API
        message_length = len(user_message.split())
        if message_length > 8:  # Complex questions
            
            # Try OpenAI first
            ai_response = self.call_openai_api(user_message)
            if ai_response:
                return ai_response, "openai"
            
            # Fallback to Cohere
            ai_response = self.call_cohere_api(user_message)
            if ai_response:
                return ai_response, "cohere"
        
        # Step 3: Final fallback - generic helpful response
        fallback_response = f"""Em há»i hay quÃ¡! Vá» váº¥n Ä‘á» nÃ y, cÃ´ nghÄ© em nÃªn:
1. Luyá»‡n táº­p thÆ°á»ng xuyÃªn má»—i ngÃ y
2. Äá»«ng ngáº¡i há»i khi chÆ°a hiá»ƒu
3. TÃ¬m hiá»ƒu thÃªm qua sÃ¡ch bÃ¡o, phim áº£nh

Em cÃ³ thá»ƒ há»i cÃ´ cá»¥ thá»ƒ hÆ¡n Ä‘Æ°á»£c khÃ´ng? VÃ­ dá»¥ vá» phÃ¡t Ã¢m, tá»« vá»±ng, hay ngá»¯ phÃ¡p?"""
        
        return fallback_response, "fallback"

# Global teacher instance
teacher = HybridVietnameseTeacher()

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        user_message = data.get('message', '').strip()
        
        if not user_message:
            return jsonify({
                'error': 'Empty message',
                'response': 'Em hÃ£y nÃ³i gÃ¬ Ä‘Ã³ Ä‘á»ƒ cÃ´ cÃ³ thá»ƒ giÃºp em nhÃ©!'
            }), 400
        
        # Generate response
        response, source = teacher.generate_response(user_message)
        
        # Log conversation
        teacher.conversation_history.append({
            'timestamp': datetime.now().isoformat(),
            'user': user_message,
            'bot': response,
            'source': source
        })
        
        return jsonify({
            'response': response,
            'source': source,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'error': str(e),
            'response': 'Xin lá»—i em, cÃ´ gáº·p váº¥n Ä‘á» ká»¹ thuáº­t. Em thá»­ láº¡i sau nhÃ©!'
        }), 500

@app.route('/history', methods=['GET'])
def get_history():
    """Get conversation history"""
    return jsonify({
        'conversations': teacher.conversation_history[-10:],  # Last 10
        'total': len(teacher.conversation_history)
    })

@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        'status': 'healthy',
        'local_responses': len(teacher.local_responses),
        'openai_available': bool(OPENAI_API_KEY),
        'cohere_available': bool(COHERE_API_KEY)
    })

@app.route('/', methods=['GET'])
def root():
    return jsonify({
        'name': 'Hybrid Vietnamese Teacher AI',
        'description': 'Smart fallback system: Local -> Cloud API -> Fallback',
        'features': [
            'Fast local responses for common questions',
            'Cloud AI for complex queries', 
            'Always has a helpful response'
        ]
    })

if __name__ == '__main__':
    print("ðŸ‡»ðŸ‡³ Hybrid Vietnamese Teacher AI")
    print("ðŸ’¡ Local responses + Cloud AI fallback")
    print("ðŸ”‘ Set OPENAI_API_KEY or COHERE_API_KEY for cloud features")
    
    app.run(host='0.0.0.0', port=5001, debug=False)